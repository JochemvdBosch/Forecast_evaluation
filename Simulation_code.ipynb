{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c475a813",
   "metadata": {},
   "source": [
    "# Forecast evaluation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8468a1",
   "metadata": {},
   "source": [
    "Simulating the forecaste evaluation time takes a significant time. This program is only for simulation and is slightly faster. This is because the horizon is equal to 1, so we can set the bandwidth parameter of the Bartlett kernel equal to zero. The three models are also seperate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ede94",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a2a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7a9e2",
   "metadata": {},
   "source": [
    "## Non-linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47640dd",
   "metadata": {},
   "source": [
    "These three models transform the vector of explanatory variables $S_t$ into a vector of nonlinear transformed variables $G(S_t;\\varphi)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57340686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TR_model(S_t, gamma):\n",
    "    return (S_t >= gamma).astype(float).reshape(-1, 1)\n",
    "\n",
    "def LSTR_model(S_t,gamma,tau):\n",
    "    return ((1+np.exp(-tau * (S_t-gamma)))**-1).reshape(-1, 1)\n",
    "\n",
    "def ESTR_model(S_t,gamma,tau):\n",
    "    return (1-np.exp(-tau * (S_t-gamma)**2)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7215b6",
   "metadata": {},
   "source": [
    "## Test statistics TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5af25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_g_theta_TR(S_t, # Vector of S_t\n",
    "                L_t, # Vector of loss function\n",
    "                R_size, # Integer\n",
    "                P_size, # Integer\n",
    "                h_size, # Integer\n",
    "                ):\n",
    "\n",
    "    # Simulate a matrix of the standard normal distribution\n",
    "    v_t = np.random.normal(0,1,(P_size,iterations_CV))\n",
    "    \n",
    "    # Initialize the critical values with a minimum value \n",
    "    crit_values = np.full(iterations_CV,-100)\n",
    "        \n",
    "    # Initialize the array for the W_P's\n",
    "    W_P = np.zeros(grid_elements)\n",
    "        \n",
    "    # Create an array of gamma value that are used in the for loop\n",
    "    gamma_quantile = np.linspace(0.15,0.85,grid_elements)\n",
    "    \n",
    "    # Loop over every parameter value to get the W_P's and the updated critical values \n",
    "    for i in range(grid_elements):\n",
    "        W_P[i], W_P_j = cal_test_statistic_TR(S_t, L_t, R_size, P_size, h_size, v_t, np.quantile(S_t,gamma_quantile[i]))\n",
    "        crit_values = np.maximum(crit_values, W_P_j)\n",
    "    \n",
    "    # Get the test statistic of all W_P values\n",
    "    g_theta = max(W_P)\n",
    "    \n",
    "    # Sort the Monte Carlo simulations and get critical value\n",
    "    crit_values.sort()\n",
    "    final_crit_value = crit_values[round(0.95 * iterations_CV)-1]\n",
    "    \n",
    "    # Check if the test statistic \n",
    "    if (g_theta > final_crit_value):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "881ef0ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cal_test_statistic_TR(S_t, #vector of S_t\n",
    "                       L_t, #vector of loss function\n",
    "                       R_size, #integer\n",
    "                       P_size, #integer\n",
    "                       h_size, #integer\n",
    "                       v_t, #matrix of standard normal distribution\n",
    "                       gamma, #gamma parameter\n",
    "                       ):\n",
    "    \n",
    "    # Initialize the matrix of lambda_sum, V_sum, M_sum\n",
    "    lambda_sum = np.zeros((2,iterations_CV))\n",
    "    V_sum = np.zeros((2,2))\n",
    "    M_sum = np.zeros((2,2))\n",
    "    \n",
    "    # Make a vector of ones for X_t\n",
    "    X_t = np.ones((len(S_t),1))\n",
    "    \n",
    "    # Get psi (scalar)\n",
    "    Q_t = np.column_stack((X_t,np.multiply(X_t,TR_model(S_t,gamma))))\n",
    "    psi = np.column_stack(estimateBeta(Q_t[R_size:R_size+P_size+h_size],L_t))\n",
    "\n",
    "    # Loop over t\n",
    "    for t in range(R_size,R_size+P_size):\n",
    "\n",
    "        # Select X, S, Y from a certain time range\n",
    "        X_sel = X_t[t-R_size:t]\n",
    "        S_sel = S_t[t-R_size:t]\n",
    "        L_sel = np.column_stack(L_t[t-R_size])        \n",
    "        \n",
    "        # Get Q_sel\n",
    "        Q_sel = np.column_stack((X_sel,np.multiply(X_sel,TR_model(S_sel,gamma))))\n",
    "        \n",
    "        # Get residuals\n",
    "        residual_sel = L_sel - np.column_stack(Q_sel[-1]) @ np.transpose(psi)\n",
    "        \n",
    "        # Get score\n",
    "        score = np.transpose(np.column_stack(Q_sel[-1])) * residual_sel\n",
    "        \n",
    "        # Get lambda_sum, V_sum and M_sum\n",
    "        lambda_sum += score * v_t[t-R_size,:]\n",
    "        V_sum += score * np.transpose(score)\n",
    "        M_sum += Q_sel[-1] * np.transpose(np.column_stack(Q_sel[-1]))\n",
    "     \n",
    "    # Set Hr to I2\n",
    "    Hr = np.identity(2)\n",
    "\n",
    "    # Get V_P and M_P\n",
    "    V_P = V_sum / P_size\n",
    "    M_P = M_sum / P_size\n",
    "\n",
    "    # Get Vstar\n",
    "    V_star = np.linalg.inv(M_P) @ V_P @ np.linalg.inv(M_P)\n",
    "    \n",
    "    # Get Wp\n",
    "    W_P = P_size * (psi @ Hr @ np.linalg.inv(np.transpose(Hr) @ V_star @ Hr) @ np.transpose(Hr) @ np.transpose(psi))\n",
    "    \n",
    "    # Get W_P_j\n",
    "    lambda_P = (lambda_sum /P_size**0.5).T\n",
    "    W_P_j = np.sum(np.matmul(lambda_P, np.linalg.inv(M_P) @ Hr @ np.linalg.inv(np.transpose(Hr) @ V_star @ Hr) @ np.transpose(Hr) @ np.linalg.inv(M_P)) * lambda_P,axis=1)\n",
    "    \n",
    "    # Return the test statistic and critical values\n",
    "    return W_P, W_P_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da5ac6",
   "metadata": {},
   "source": [
    "## Test statistics LSTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6567d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_g_theta_LSTR(S_t, # Vector of S_t\n",
    "                L_t, # Vector of loss function\n",
    "                R_size, # Integer\n",
    "                P_size, # Integer\n",
    "                h_size, # Integer\n",
    "                ):\n",
    "        \n",
    "    # Simulate a matrix of the standard normal distribution\n",
    "    v_t = np.random.normal(0,1,(P_size,iterations_CV))\n",
    "    \n",
    "    # Initialize the critical values with a minimum value \n",
    "    crit_values = np.full(iterations_CV,-100)\n",
    "    \n",
    "    # Initialize the array for the W_P's\n",
    "    W_P = np.zeros(grid_elements**2)\n",
    "        \n",
    "    # Create an array of gamma and tau values that are used in the for loop\n",
    "    gamma_quantile = np.linspace(0.15,0.85,grid_elements)\n",
    "    tau = np.linspace(0.1,5,grid_elements)\n",
    "       \n",
    "    # Loop over every parameter value to get the W_P's and the updated critical values\n",
    "    for i in range(grid_elements):\n",
    "        for j in range(grid_elements):\n",
    "            W_P[i*grid_elements+j], W_P_j = cal_test_statistic_LSTR(S_t, L_t, R_size, P_size, h_size, v_t, np.quantile(S_t,gamma_quantile[i]),tau[j])\n",
    "            crit_values = np.maximum(crit_values, W_P_j)\n",
    "    \n",
    "    # Get the test statistic of all W_P values\n",
    "    g_theta = max(W_P)\n",
    "    \n",
    "    # Sort the Monte Carlo simulations and get critical value\n",
    "    crit_values.sort()\n",
    "    final_crit_value = crit_values[round(0.95 * iterations_CV)-1]\n",
    "    \n",
    "    # Check if the test statistic \n",
    "    if (g_theta > final_crit_value):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea70819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_statistic_LSTR(S_t, #vector of S_t\n",
    "                       L_t, #vector of loss function\n",
    "                       R_size, #integer\n",
    "                       P_size, #integer\n",
    "                       h_size, #integer\n",
    "                       v_t, #matrix of standard normal distribution\n",
    "                       gamma, #gamma parameter\n",
    "                       tau=0  #tau parameter\n",
    "                       ):\n",
    "    \n",
    "    # Initialize the matrix of lambda_sum, V_sum, M_sum\n",
    "    lambda_sum = np.zeros((2,iterations_CV))\n",
    "    V_sum = np.zeros((2,2))\n",
    "    M_sum = np.zeros((2,2))\n",
    "    \n",
    "    # Make a vector of ones for X_t\n",
    "    X_t = np.ones((len(S_t),1))\n",
    "    \n",
    "    # Get psi (scalar)\n",
    "    Q_t = np.column_stack((X_t,np.multiply(X_t,LSTR_model(S_t,gamma,tau))))\n",
    "    psi = np.column_stack(estimateBeta(Q_t[R_size:R_size+P_size+h_size],L_t))\n",
    "\n",
    "    # Loop over t\n",
    "    for t in range(R_size,R_size+P_size):\n",
    "\n",
    "        # Select X, S, Y from a certain time range\n",
    "        X_sel = X_t[t-R_size:t]\n",
    "        S_sel = S_t[t-R_size:t]\n",
    "        L_sel = np.column_stack(L_t[t-R_size])        \n",
    "        \n",
    "        # Get Q_sel\n",
    "        Q_sel = np.column_stack((X_sel,np.multiply(X_sel,LSTR_model(S_sel,gamma,tau))))\n",
    "        \n",
    "        # Get residuals\n",
    "        residual_sel = L_sel - np.column_stack(Q_sel[-1]) @ np.transpose(psi)\n",
    "        \n",
    "        # Get score\n",
    "        score = np.transpose(np.column_stack(Q_sel[-1])) * residual_sel\n",
    "        \n",
    "        # Get lambda_sum, V_sum and M_sum\n",
    "        lambda_sum += score * v_t[t-R_size,:]\n",
    "        V_sum += score * np.transpose(score)\n",
    "        M_sum += Q_sel[-1] * np.transpose(np.column_stack(Q_sel[-1]))\n",
    "            \n",
    "    # Set Hr to I2\n",
    "    Hr = np.identity(2)\n",
    "\n",
    "    # Get V_P and M_P\n",
    "    V_P = V_sum / P_size\n",
    "    M_P = M_sum / P_size\n",
    "    \n",
    "    # Get Vstar\n",
    "    V_star = np.linalg.inv(M_P) @ V_P @ np.linalg.inv(M_P)\n",
    "    \n",
    "    # Get Wp\n",
    "    W_P = P_size * (psi @ Hr @ np.linalg.inv(np.transpose(Hr) @ V_star @ Hr) @ np.transpose(Hr) @ np.transpose(psi))\n",
    "\n",
    "    # Get W_P_j\n",
    "    lambda_P = (lambda_sum / P_size**0.5).T\n",
    "    W_P_j = np.sum(np.matmul(lambda_P, np.linalg.inv(M_P) @ Hr @ np.linalg.inv(np.transpose(Hr) @ V_star @ Hr) @ np.transpose(Hr) @ np.linalg.inv(M_P)) * lambda_P,axis=1)\n",
    "\n",
    "    # Return the test statistic and critical values\n",
    "    return W_P, W_P_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac755a8",
   "metadata": {},
   "source": [
    "## Test statistics ESTR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65de901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_g_theta_ESTR(S_t, # Vector of S_t\n",
    "                L_t, # Vector of loss function\n",
    "                R_size, # Integer\n",
    "                P_size, # Integer\n",
    "                h_size, # Integer\n",
    "                ):\n",
    "        \n",
    "    # Simulate a matrix of the standard normal distribution\n",
    "    v_t = np.random.normal(0,1,(P_size,iterations_CV))\n",
    "    \n",
    "    # Initialize the critical values with a minimum value \n",
    "    crit_values = np.full(iterations_CV,-100)\n",
    "    \n",
    "    # Initialize the array for the W_P's\n",
    "    W_P = np.zeros(grid_elements**2)\n",
    "        \n",
    "    # Create an array of gamma and tau values that are used in the for loop\n",
    "    gamma_quantile = np.linspace(0.15,0.85,grid_elements)\n",
    "    tau = np.linspace(0.1,5,grid_elements)\n",
    "       \n",
    "    # Loop over every parameter value to get the W_P's and the updated critical values\n",
    "    for i in range(grid_elements):\n",
    "        for j in range(grid_elements):\n",
    "            W_P[i*grid_elements+j], W_P_j = cal_test_statistic_ESTR(S_t, L_t, R_size, P_size, h_size, v_t, np.quantile(S_t,gamma_quantile[i]),tau[j])\n",
    "            crit_values = np.maximum(crit_values, W_P_j)\n",
    "    \n",
    "    # Get the test statistic of all W_P values\n",
    "    g_theta = max(W_P)\n",
    "    \n",
    "    # Sort the Monte Carlo simulations and get critical value\n",
    "    crit_values.sort()\n",
    "    final_crit_value = crit_values[round(0.95 * iterations_CV)-1]\n",
    "    \n",
    "    # Check if the test statistic \n",
    "    if (g_theta > final_crit_value):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c853230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_statistic_ESTR(S_t, #vector of S_t\n",
    "                       L_t, #vector of loss function\n",
    "                       R_size, #integer\n",
    "                       P_size, #integer\n",
    "                       h_size, #integer\n",
    "                       v_t, #matrix of standard normal distribution\n",
    "                       gamma, #gamma parameter\n",
    "                       tau=0  #tau parameter\n",
    "                       ):\n",
    "    \n",
    "    # Initialize the matrix of lambda_sum, V_sum, M_sum\n",
    "    lambda_sum = np.zeros((2,iterations_CV))\n",
    "    V_sum = np.zeros((2,2))\n",
    "    M_sum = np.zeros((2,2))\n",
    "    \n",
    "    # Make a vector of ones for X_t\n",
    "    X_t = np.ones((len(S_t),1))\n",
    "    \n",
    "    # Get psi (scalar)\n",
    "    Q_t = np.column_stack((X_t,np.multiply(X_t,ESTR_model(S_t,gamma,tau))))\n",
    "    psi = np.column_stack(estimateBeta(Q_t[R_size:R_size+P_size+h_size],L_t))\n",
    "\n",
    "    # Loop over t\n",
    "    for t in range(R_size,R_size+P_size):\n",
    "\n",
    "        # Select X, S, Y from a certain time range\n",
    "        X_sel = X_t[t-R_size:t]\n",
    "        S_sel = S_t[t-R_size:t]\n",
    "        L_sel = np.column_stack(L_t[t-R_size])        \n",
    "        \n",
    "        # Get Q_sel\n",
    "        Q_sel = np.column_stack((X_sel,np.multiply(X_sel,ESTR_model(S_sel,gamma,tau))))\n",
    "        \n",
    "        # Get residuals\n",
    "        residual_sel = L_sel - np.column_stack(Q_sel[-1]) @ np.transpose(psi)\n",
    "        \n",
    "        # Get score\n",
    "        score = np.transpose(np.column_stack(Q_sel[-1])) * residual_sel\n",
    "        \n",
    "        # Get lambda_sum, V_sum and M_sum\n",
    "        lambda_sum += score * v_t[t-R_size,:]\n",
    "        V_sum += score * np.transpose(score)\n",
    "        M_sum += Q_sel[-1] * np.transpose(np.column_stack(Q_sel[-1]))\n",
    "            \n",
    "    # Set Hr to I2\n",
    "    Hr = np.identity(2)\n",
    "\n",
    "    # Get V_P and M_P\n",
    "    V_P = V_sum / P_size\n",
    "    M_P = M_sum / P_size\n",
    "    \n",
    "    # Get Vstar\n",
    "    V_star = np.linalg.inv(M_P) @ V_P @ np.linalg.inv(M_P)\n",
    "    \n",
    "    # Get Wp\n",
    "    W_P = P_size * (psi @ Hr @ np.linalg.inv(np.transpose(Hr) @ V_star @ Hr) @ np.transpose(Hr) @ np.transpose(psi))\n",
    "\n",
    "    # Get W_P_j\n",
    "    lambda_P = (lambda_sum / P_size**0.5).T\n",
    "    W_P_j = np.sum(np.matmul(lambda_P, np.linalg.inv(M_P) @ Hr @ np.linalg.inv(np.transpose(Hr) @ V_star @ Hr) @ np.transpose(Hr) @ np.linalg.inv(M_P)) * lambda_P,axis=1)\n",
    "\n",
    "    # Return the test statistic and critical values\n",
    "    return W_P, W_P_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bedc3",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c2e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple method to estimate the OLS estimates\n",
    "def estimateBeta(Z_t,Y_t):\n",
    "    return np.linalg.inv(np.transpose(Z_t) @ Z_t) @ np.transpose(Z_t) @ Y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3dc9dae6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def MonteCarlo_1_TR(iterations,R,P,h,T):\n",
    "        \n",
    "    #define variable to keep track of amount of rejects\n",
    "    MC_array = Parallel(n_jobs=6)(delayed(MonteCarlo_iteration_TR)(iterations,R,P,h,T) for i in range(iterations))\n",
    "    \n",
    "    print(np.mean(MC_array))\n",
    "    \n",
    "def MonteCarlo_iteration_TR(iterations,R,P,h,T):\n",
    "    #simulate model, it only returns vectors:\n",
    "    sim_z1, sim_z2, sim_y_t, sim_S_t = sim_model_1(T)\n",
    "\n",
    "    delta_L = cal_delta_L_1(sim_z1, sim_z2, sim_y_t, R, P, h, T)\n",
    "        \n",
    "    return cal_g_theta_TR(S_t=sim_S_t, L_t=delta_L, R_size=R, P_size=P, h_size=h)\n",
    "\n",
    "\n",
    "def sim_model_1(T):\n",
    "    y_t = np.zeros((T,1))\n",
    "    delta1 = delta2 = v = 1\n",
    "    z1 = np.random.normal(0,1,(T,1))\n",
    "    z2 = np.random.normal(0,1,(T,1))\n",
    "    S_t = np.random.normal(0,1,(T,1))\n",
    "    \n",
    "    y_t = v + delta1 + z1 + delta2 + z2 + np.random.normal(0, 1, (T,1))\n",
    "\n",
    "    #return vector values\n",
    "    return z1, z2, y_t, S_t\n",
    "\n",
    "\n",
    "def cal_delta_L_1(sim_z1, sim_z2, sim_y_t, R, P, h, T):\n",
    "    sim_z1 = np.column_stack([np.ones((T,1)),sim_z1])\n",
    "    sim_z2 = np.column_stack([np.ones((T,1)),sim_z2])\n",
    "    \n",
    "    delta_L = np.zeros((P,1))\n",
    "    \n",
    "    for t in range(R, T+1-h):\n",
    "        z1_sel = sim_z1[t-R:t]\n",
    "        z2_sel = sim_z2[t-R:t]\n",
    "        y_sel = sim_y_t[t-R+h:t+h]\n",
    "        \n",
    "        beta_1 = estimateBeta(z1_sel,y_sel)\n",
    "        beta_2 = estimateBeta(z2_sel,y_sel)\n",
    "\n",
    "        forecast1 = beta_1[0] + z1_sel[-1,1] * beta_1[1]\n",
    "        forecast2 = beta_2[0] + z2_sel[-1,1] * beta_2[1]\n",
    "\n",
    "        delta_L[t-R] = (y_sel[-1] - forecast1)**2 - (y_sel[-1] - forecast2)**2\n",
    "    \n",
    "    return delta_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b7e6e",
   "metadata": {},
   "source": [
    "Choose one of the following model types:\n",
    "1. \"TR\"\n",
    "2. \"LSTR\"\n",
    "3. \"ESTR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53b71d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#simulation speed:\n",
    "MC_iterations = 400\n",
    "grid_elements = 20\n",
    "iterations_CV = 200\n",
    "\n",
    "# You can modify these variables\n",
    "R_MC = 25\n",
    "P_MC = 100\n",
    "\n",
    "# Do not modify these variables\n",
    "h_MC = 1\n",
    "T_MC = R_MC + P_MC + h_MC - 1\n",
    "\n",
    "# MonteCarlo_1(MC_iterations, R_MC, P_MC,h_MC,T_MC,\"TR\")\n",
    "MonteCarlo_1_TR(MC_iterations, R_MC, P_MC,h_MC,T_MC)\n",
    "# MonteCarlo_1_ESTR(MC_iterations, R_MC, P_MC,h_MC,T_MC)\n",
    "# MonteCarlo_1_LSTR(MC_iterations, R_MC, P_MC,h_MC,T_MC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
