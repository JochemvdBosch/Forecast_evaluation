{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c475a813",
   "metadata": {},
   "source": [
    "# Forecast evaluation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ede94",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18a2a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7a9e2",
   "metadata": {},
   "source": [
    "## Non-linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57340686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TR_model(S_t, gamma):\n",
    "    # Return a vector of outcomes of the TR model\n",
    "    return (S_t >= gamma).astype(float).reshape(-1, 1)\n",
    "\n",
    "def LSTR_model(S_t,gamma,tau):\n",
    "    # Return a vector of outcomes of the LSTR model\n",
    "    return ((1+np.exp(-tau * (S_t-gamma)))**-1).reshape(-1, 1)\n",
    "\n",
    "def ESTR_model(S_t,gamma,tau):\n",
    "    # Return a vector of outcomes of the ESTR model\n",
    "    return (1-np.exp(-tau * (S_t-gamma)**2)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f775785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlin_model(model_type, S_t, gamma, tau):\n",
    "    \n",
    "    # Detect which model type it should use according to model_type\n",
    "    if (model_type == \"TR\"):\n",
    "        return TR_model(S_t,gamma)\n",
    "        \n",
    "    elif (model_type == \"LSTR\"):\n",
    "        return LSTR_model(S_t,gamma,tau)\n",
    "        \n",
    "    elif (model_type == \"ESTR\"):\n",
    "        return ESTR_model(S_t,gamma,tau)\n",
    "        \n",
    "    # If we pass another model that is not included, we give an error\n",
    "    else:\n",
    "        raise Exception(\"Model type unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7215b6",
   "metadata": {},
   "source": [
    "## Test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65c2e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple method to estimate the OLS estimates\n",
    "def estimateBeta(Z_t,Y_t):\n",
    "    return np.linalg.inv(np.transpose(Z_t) @ Z_t) @ np.transpose(Z_t) @ Y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5af25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_g_theta(S_t, # Vector of S_t\n",
    "                L_t, # Vector of loss function\n",
    "                R_size, # Integer\n",
    "                P_size, # Integer\n",
    "                h_size, # Integer\n",
    "                model_type # String of model type\n",
    "                ):\n",
    "    \n",
    "    # Determine the size of B\n",
    "    B_size = round(4*(P_size/100)**(2/9)+1)\n",
    "    \n",
    "    # Simulate a matrix of the standard normal distribution\n",
    "    v_t = np.random.normal(0,1,(P_size+B_size,iterations_CV))\n",
    "    \n",
    "    # Initialize the critical values with a minimum value \n",
    "    crit_values = np.full(iterations_CV,-100)\n",
    "\n",
    "    # Check which model we should use;\n",
    "    if (model_type == \"TR\"):\n",
    "        \n",
    "        # Initialize the array for the W_P's\n",
    "        W_P = np.zeros(grid_elements)\n",
    "        \n",
    "        # Create an array of gamma value that are used in the for loop\n",
    "        gamma_quantile = np.linspace(0.15,0.85,grid_elements)\n",
    "    \n",
    "        # Loop over every parameter value to get the W_P's and the updated critical values \n",
    "        for i in range(grid_elements):\n",
    "            W_P[i], W_P_j = cal_test_statistic(S_t, L_t, R_size, P_size, h_size, B_size, v_t, model_type, np.quantile(S_t,gamma_quantile[i]))\n",
    "            crit_values = np.maximum(crit_values, W_P_j)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Initialize the array for the W_P's\n",
    "        W_P = np.zeros(grid_elements**2)\n",
    "        \n",
    "        # Create an array of gamma and tau values that are used in the for loop\n",
    "        gamma_quantile = np.linspace(0.15,0.85,grid_elements)\n",
    "        tau = np.linspace(0.1,5,grid_elements)\n",
    "        \n",
    "        # Loop over every parameter value to get the W_P's and the updated critical values\n",
    "        for i in range(grid_elements):\n",
    "            for j in range(grid_elements):\n",
    "                W_P[i*grid_elements+j], W_P_j = cal_test_statistic(S_t, L_t, R_size, P_size, h_size, B_size, v_t, model_type, np.quantile(S_t,gamma_quantile[i]),tau[j])\n",
    "                crit_values = np.maximum(crit_values, W_P_j)\n",
    "    \n",
    "    # Get the test statistic of all W_P values\n",
    "    g_theta = max(W_P)\n",
    "    \n",
    "    # Sort the Monte Carlo simulations and get critical value\n",
    "    crit_values.sort()\n",
    "    final_crit_value = crit_values[round(0.95 * iterations_CV)-1]\n",
    "\n",
    "    # Check if the test statistic \n",
    "    if (g_theta > final_crit_value):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "881ef0ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cal_test_statistic(S_t, #vector of S_t\n",
    "                       L_t, #vector of loss function\n",
    "                       R_size, #integer\n",
    "                       P_size, #integer\n",
    "                       h_size, #integer\n",
    "                       B_size, #integer\n",
    "                       v_t, #matrix of standard normal distribution\n",
    "                       model_type, #String of model type\n",
    "                       gamma, #gamma parameter\n",
    "                       tau=0  #tau parameter\n",
    "                       ):\n",
    "        \n",
    "    # Initialize the matrix of lambda_sum, V_sum, M_sum\n",
    "    lambda_sum = np.zeros((2,iterations_CV))\n",
    "    V_sum = np.zeros((2,2))\n",
    "    M_sum = np.zeros((2,2))\n",
    "    \n",
    "    # Make a vector of ones for X_t\n",
    "    X_t = np.ones((len(S_t),1))\n",
    "    \n",
    "    # Get psi (scalar)\n",
    "    Q_t = np.column_stack((X_t,np.multiply(X_t,nonlin_model(model_type,S_t,gamma,tau))))\n",
    "    psi = np.column_stack(estimateBeta(Q_t[R_size-h_size:R_size+P_size-h_size],L_t))\n",
    "\n",
    "    # Loop over t\n",
    "    for t in range(R_size,R_size+P_size):\n",
    "\n",
    "        # Select X, S, Y from a certain time range\n",
    "        X_sel = X_t[t-R_size:t]\n",
    "        S_sel = S_t[t-R_size:t]\n",
    "        L_sel = np.column_stack(L_t[t-R_size])        \n",
    "        \n",
    "        # Get Q_sel\n",
    "        Q_sel = Q_t[t-R_size:t]\n",
    "\n",
    "        # Get residuals\n",
    "        residual_sel = L_sel - np.column_stack(Q_sel[-1]) @ np.transpose(psi)\n",
    "\n",
    "        # Get score\n",
    "        score = np.transpose(np.column_stack(Q_sel[-1])) * residual_sel\n",
    "        \n",
    "        # Get V and M sum\n",
    "        V_sum += score * np.transpose(score)\n",
    "        M_sum += Q_sel[-1] * np.transpose(np.column_stack(Q_sel[-1]))\n",
    "\n",
    "        # Loop over all B\n",
    "        for b in range(0,B_size+1):\n",
    "            lambda_sum += score * v_t[t+b-R_size,:]\n",
    "            \n",
    "    # Set Hr to I2\n",
    "    Hr = np.identity(2)\n",
    "\n",
    "    # Get V_P and M_P\n",
    "    V_P = V_sum / P_size\n",
    "    M_P = M_sum / P_size\n",
    "\n",
    "    # Get Vstar\n",
    "    V_star = np.linalg.inv(M_P) @ V_P @ np.linalg.inv(M_P)\n",
    "\n",
    "    # Get Wp\n",
    "    W_P = P_size * (psi @ Hr @ np.linalg.inv(np.transpose(Hr) @ V_star @ Hr) @ np.transpose(Hr) @ np.transpose(psi))\n",
    "\n",
    "    # Get W_P_j\n",
    "    lambda_P = (lambda_sum / ((P_size*(1+B_size))**0.5)).T\n",
    "    W_P_j = np.sum(np.matmul(lambda_P, np.linalg.inv(M_P) @ Hr @ np.linalg.inv(np.transpose(Hr) @ V_star @ Hr) @ np.transpose(Hr) @ np.linalg.inv(M_P)) * lambda_P,axis=1)\n",
    "    \n",
    "    # Return the test statistic and critical values\n",
    "    return W_P, W_P_j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
